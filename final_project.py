# -*- coding: utf-8 -*-
"""Final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rFz_-J3sv-e6zaVhDvidWHIA4_RcLkQh
"""

# Commented out IPython magic to ensure Python compatibility.
# importing things not in the colab
from os.path import exists
from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())
cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\.\([0-9]*\)\.\([0-9]*\)$/cu\1\2/'
accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'

!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision
import torch

!pip install pillow==4.1.1
# %reload_ext autoreload
# %autoreload

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu") 
print(device)

# check if CUDA is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

# Commented out IPython magic to ensure Python compatibility.
# Imports here
# %matplotlib inline

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
import os
import collections
import torchvision.models as models
from torch import nn
from PIL import Image
import torch.nn.functional as F

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive')

train_dir = '/content/drive/My Drive/Colab Notebooks/flower_data/train'
valid_dir = '/content/drive/My Drive/Colab Notebooks/flower_data/valid'
test_dir = '/content/drive/My Drive/Colab Notebooks/flower_data/test'

# TODO: Define your transforms for the training and validation sets
train_transforms = transforms.Compose([transforms.Resize(256),
                                       transforms.CenterCrop(224),
                                       #transforms.RandomHorizontalFlip(),
                                       #transforms.RandomRotation(20),
                                       transforms.ToTensor(),
                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])

valid_transforms = transforms.Compose([transforms.Resize(256),
                                       transforms.CenterCrop(224),
                                       transforms.ToTensor(),
                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])

test_transforms = transforms.Compose([transforms.Resize(256),
                                       transforms.CenterCrop(224),
                                       transforms.ToTensor(),
                                       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])

# Load the datasets with ImageFolder
train_data = torchvision.datasets.ImageFolder(train_dir, transform=train_transforms)
valid_data = torchvision.datasets.ImageFolder(valid_dir, transform=valid_transforms)
test_data = torchvision.datasets.ImageFolder(test_dir, transform=test_transforms)

# Using the image datasets and the trainforms, define the dataloaders
batch_size = 100
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)
valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size)

import json

with open('/content/drive/My Drive/Colab Notebooks/cat_to_name.json', 'r') as f:
    cat_to_name = json.load(f)

# class to idx
def class_to_idx(dir):
    # find the order in which directories are
    directories = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]
    directories.sort()
    class_to_idx = {i: directories[i] for i in range(len(directories))}
    return class_to_idx

class_to_idx = class_to_idx(train_dir)

print(class_to_idx)

# load features of pretrained vgg network 
# loads only the feature extraction part of vgg
vgg = models.vgg19(pretrained=True, input_shape=(3, 250, 180)).features

# freeze vgg parameters - so that backprop doesn't change them
for param in vgg.parameters() :
    param.requires_grad_(False)

# Runs an image forward through the model
# and gets features for given layers
def get_features(image, model, last_layer=None) :

    x = image
   
    for name, layer in model._modules.items() :
        x = layer(x)
        
    return x

# move the model to GPU, if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

vgg.to(device)
print(device)

# parameters
num_classes = 102
num_features = 512 * 7 * 7 
fc1_size =  2048
fc2_size = 512
#fc3_size = 126

# classifier part of the network
class Classifier(nn.Module) : 
    def __init__(self) :
        super(Classifier, self).__init__()
        # first fully connected layer
        self.fc1 = nn.Linear(num_features, fc1_size)
        
        # second fully connected layer
        self.fc2 = nn.Linear(fc1_size, fc2_size)
        
        # third fully connected layer
        #self.fc3 = nn.Linear(fc2_size, fc3_size)
        
        # output layer
        self.output = nn.Linear(fc2_size, num_classes)
        
        # dropout layer
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x) :
        # flatten input vector
       
        x = x.view(x.shape[0], -1)
       
        # pass features through first layer and apply relu
        x = F.relu(self.fc1(x))
        
        # apply dropout
        x = self.dropout(x)
        
        # pass features through second layer and apply relu
        x = F.relu(self.fc2(x))
        
        # apply dropout
        x = self.dropout(x)
        
        # pass features through third layer and apply relu
        #x = F.relu(self.fc3(x))
        
        # apply dropout
        #x = self.dropout(x)
        
        # pass through second layer
        x = self.output(x)
        
        return x

# defining classifier
classifier = Classifier()

# move classifier to gpu
if train_on_gpu:
    classifier.cuda()

# defining loss function
criterion = nn.CrossEntropyLoss()

# defining optimizer
optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)

# defining scheduler for updating learning rate
# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.01)

# training
n_epochs = 10

# training and validation losses through epochs
training_losses = []
validation_losses = []

# minimal validation loss
min_valid_loss = np.Inf

for epoch in range(n_epochs) :
    
    # keeping track of train and validation losses
    train_loss = 0.0
    valid_loss = 0.0
    
    #################
    # training loop #
    #################
    
    # put classifier in training mode
    classifier.train()
    
    for data, labels in train_loader :
      
      # move to gpu
      if train_on_gpu:
          data, labels = data.cuda(), labels.cuda()

      # reset gradients
      optimizer.zero_grad()

      # feature extraction
      features = get_features(data, vgg)

      # forward pass through classifier
      output = classifier(features)

      # calculate loss
      loss = criterion(output, labels)

      # calculate the gradient with respect to loss
      loss.backward()

      # take SGD step
      optimizer.step()

      # update training loss
      train_loss += loss.item() * data.shape[0]

    ###################
    # validation loop #
    ###################
    
    with torch.no_grad() :
      # put classifier in evaluation mode
      classifier.eval()
      
      valid_accuracy = 0
      correct = 0
      total = 0
      for data, labels in valid_loader :

          # move to gpu
          if train_on_gpu:
              data, labels = data.cuda(), labels.cuda()

          # feature extraction
          features = get_features(data, vgg)

          # forward pass through classifier
          output = classifier(features)

          # calculate loss
          loss = criterion(output, labels)

          # update validation loss
          valid_loss += loss.item() * data.shape[0]
          
          # calculate validation accuracy
          
          # probability scores
          ps = torch.sigmoid(output)
          
          # top class
          top_p, top_class = ps.topk(1, dim=1)
         
          
          # equality
          equals = top_class == labels.view(*top_class.shape)
         
          # accuracy
          correct += (equals.type(torch.FloatTensor)).sum().item()
         
          total += data.shape[0]
    
    # average training and validation losses in this epoch
    train_avg_loss = train_loss / len(train_loader.dataset)
    valid_avg_loss = valid_loss / len(valid_loader.dataset)
    
    valid_accuracy = correct/total
    
    # print average losses
    print('Epoch {} \tTraining Loss: {} \t Validation Loss: {} \tValidation Accuracy: {}'.format(epoch + 1, train_avg_loss, valid_avg_loss, valid_accuracy))
    
    # update train and validation arrays
    training_losses.append(train_avg_loss) 
    validation_losses.append(valid_avg_loss) 
    
    # saving the model if validation loss has decreased
    
    if (valid_avg_loss < min_valid_loss) :
      torch.save({
          'base' : 'vgg',
          'state_dict' : classifier.state_dict(),
          'num_features' : num_features,
          'fc1' : fc1_size,
          'fc2' : fc2_size,
          #'fc3' : fc3_size,
          'num_classes' : num_classes,
          'optimizer_state_dict' : optimizer.state_dict(),
          'loss' : valid_avg_loss,
          'class_to_idx' : class_to_idx
      }, '/content/drive/My Drive/Colab Notebooks/checkpoint1.pt')
      print('-----------')
      print('Model saved')
      print('-----------')
      min_valid_loss = valid_avg_loss

# evaluate model 
def evaluate(model, loader, eval_type):
  with torch.no_grad() :
      # put model in evaluation mode
      model.eval()
      
      accuracy = 0
      correct = 0
      total = 0
      
      for data, labels in loader :

          # move to gpu
          if train_on_gpu:
              data, labels = data.cuda(), labels.cuda()

          # feature extraction
          features = get_features(data, vgg)

          # forward pass through classifier
          output = classifier(features)

          # calculate loss
          loss = criterion(output, labels)

          # update validation loss
          valid_loss += loss.item() * data.shape[0]
                    
          # probability scores
          ps = torch.exp(output)
          
          # top class
          top_p, top_class = ps.topk(1, dim=1)
         
          
          # equality
          equals = top_class == labels.view(*top_class.shape)
         
          # accuracy
          correct += (equals.type(torch.FloatTensor)).sum().item()
         
          total += data.shape[0]
    
    # average training and validation losses in this epoch
    train_avg_loss = train_loss / len(train_loader.dataset)
    valid_avg_loss = valid_loss / len(valid_loader.dataset)
    
    valid_accuracy = correct/total
    
    # print average losses
    print('Epoch {} \tTraining Loss: {} \t Validation Loss: {} \tValidation Accuracy: {}'.format(epoch + 1, train_avg_loss, valid_avg_loss, valid_accuracy))
    
    # update train and validation arrays
    training_losses.append(train_avg_loss) 
    validation_losses.append(valid_avg_loss) 
    
    # saving the model if validation loss has decreased
    
    if (valid_avg_loss < min_valid_loss) :
      torch.save({
          'base' : 'vgg',
          'state_dict' : classifier.state_dict(),
          'num_features' : num_features,
          'fc1' : fc1_size,
          'fc2' : fc2_size,
          #'fc3' : fc3_size,
          'num_classes' : num_classes,
          'optimizer_state_dict' : optimizer.state_dict(),
          'loss' : valid_avg_loss,
          'class_to_idx' : class_to_idx
      }, '/content/drive/My Drive/Colab Notebooks/checkpoint1.pt')
      print('-----------')
      print('Model saved')
      print('-----------')
      min_valid_loss = valid_avg_loss

plt.plot(training_losses, label='Training loss')
plt.plot(validation_losses, label='Validation loss')
plt.legend(frameon=False)

# function to load the checkpoint
def load_checkpoint(path) :
  
  chpt = torch.load(path)
  
  # load base architecture
  if (chpt['base'] == 'vgg') : 
    model = models.vgg19(pretrained=True)
    
    for param in model.parameters() : 
      param.requires_grad = False
      
  # creating the classifier
  num_features = chpt['num_features']
  fc1 = chpt['fc1']
  fc2 = chpt['fc2']
  num_classes = chpt['num_classes']
  
  classifier = nn.Sequential(collections.OrderedDict([('fc1', nn.Linear(num_features, fc1)),
                                          ('relu', nn.ReLU()),
                                          ('fc2', nn.Linear(fc1, fc2)),
                                          ('relu', nn.ReLU()),
                                          ('output', nn.Linear(fc2, num_classes)),
                                          ('softmax', nn.LogSoftmax(dim=1))
                                         ]))
                             
  # load saved parameters 
  classifier.load_state_dict(chpt['state_dict'])
    
  # put custom classifier on top of pretrained feature extractor
  model.classifier = classifier
                             
  # add class to idx mapping
  model.class_to_idx = chpt['class_to_idx']                          
    
  
  return model

model = load_checkpoint('/content/drive/My Drive/Colab Notebooks/checkpoint1.pt')
# using it only for evaluation, this speeds up calculations
model.eval()

##############
# test loop #
#############
with torch.no_grad() :
      # put model in evaluation model
      model.eval()
      
      test_accuracy = 0
      correct = 0
      total = 0
      
      i = 0
      for data, labels in test_loader :
        
          print(i)
          i += 1
          logits = model.forward(data)
          ps = torch.exp(logits)
          
          top_p, top_class = ps.topk(1, dim=1)
          
          # equality
          equals = top_class == labels.view(*top_class.shape)
         
          # accuracy
          correct += (equals.type(torch.FloatTensor)).sum().item()
         
          total += data.shape[0]
      
      test_accuracy = correct/total
      print('Testing accuracy:\t {}'.format(test_accuracy))



# just for checking validation accuracy
##############
# test loop #
#############
with torch.no_grad() :
      # put model in evaluation mode
      model.eval()
      
      valid_accuracy = 0
      correct = 0
      total = 0
      
      i = 0
      for data, labels in valid_loader :
        
          print(i)
          i += 1
          logits = model.forward(data)
          ps = torch.exp(logits)
          
          top_p, top_class = ps.topk(1, dim=1)
          
          # equality
          equals = top_class == labels.view(*top_class.shape)
         
          # accuracy
          correct += (equals.type(torch.FloatTensor)).sum().item()
         
          total += data.shape[0]
      
      valid_accuracy = correct/total
      print('Validation accuracy:\t {}'.format(test_accuracy))

# prepare image for prediction
def process_image(image):
    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,
        returns an Numpy array
    '''
    
    transform = transforms.Compose([transforms.Resize(256),
                                    transforms.CenterCrop(224)])
    
    image = transform(image)
    
    # turn to numpy array
    np_image = np.array(image)
    
    # Color channels of images are typically encoded as 
    # integers 0-255, but the model expected floats 0-1.
    np_image = np_image/255
    
    # normalize image
    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]
    
    np_image = np.subtract(np_image, mean)
    np_image = np.divide(np_image, std)
    
    print (np_image.shape)
    # change position of color channel
    np_image = np_image.transpose((2, 0, 1))
    print (np_image.shape)
    
    return np_image
    # TODO: Process a PIL image for use in a PyTorch model

def imshow(image, ax=None, title=None):
    """Imshow for Tensor."""
    if ax is None:
        fig, ax = plt.subplots()
    
    # PyTorch tensors assume the color channel is the first dimension
    # but matplotlib assumes is the third dimension
    image = image.transpose((1, 2, 0))
    
    print(image.shape)
    
    # Undo preprocessing
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    image = std * image + mean
    
    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed
    image = np.clip(image, 0, 1)
    
    ax.imshow(image)
    
    return ax

def predict(image_path, model, topk=5):
    ''' Predict the class (or classes) of an image using a trained deep learning model.
    '''
    
    # TODO: Implement the code to predict the class from an image file
    
    image = Image.open(path).convert('RGB')
   
    p_image = process_image(image)
   
    # convert np image to torch tensor 
    torch_img = torch.from_numpy(p_image).type(torch.FloatTensor)
    torch_img = torch_img.unsqueeze_(0)
    
    # get network output
    output = model.forward(torch_img)
    
    # get probability scores
    ps = torch.exp(output)
    
    
    print(ps)
    # get top 5 classes
    top_p, top_class = ps.topk(topk, dim=1)
    
    # split plot into 2 parts
    f, (axarr1, axarr2) = plt.subplots(1,2)
    f.subplots_adjust(wspace=0.7)
    
    # display image - takes processed image as input
    imshow(p_image, ax=axarr1)
    
    # displaying probabilities 
    probabilities = {}
 
    np_top_p = top_p.detach().numpy()
    np_top_p = np.squeeze(np_top_p)
    
    np_top_class = top_class.detach().numpy()
    np_top_class = np.squeeze(np_top_class)
    
    for i in range(topk) :
      index = model.class_to_idx[np_top_class[i]]
      name = cat_to_name[str(index)]
      probabilities[name] = np_top_p[i]
      
    print(probabilities)
      
    values = list(probabilities.values())
    names = list(probabilities.keys())

    # plot probabilities
    axarr2.barh(range(5), values, tick_label=names)
    
    plt.show()
    
    return top_class

path = '/content/drive/My Drive/Colab Notebooks/flower_data/train/1/image_06734.jpg'

print(model.class_to_idx)

predict(path, model)

print(cat_to_name['1'])

